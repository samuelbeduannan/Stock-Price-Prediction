{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ba1156",
   "metadata": {},
   "source": [
    "Use case: Predicting the close prices of stocks using the Open, High, Low and Volume of each stock.\n",
    "Dataset source: https://www.kaggle.com/mysarahmadbhat/stock-prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a659b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b323c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'open', 'high', 'low', 'close', 'volume'], dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read original data and set symbol column as the index\n",
    "data = pd.read_csv('stock_prices.csv', index_col='symbol')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5ce13c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define score tester function to test different models of Random Forest Regressor\n",
    "def score_tester(model, X_train, X_valid, y_train,y_valid):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    mae_score = mean_absolute_error(y_valid, preds)\n",
    "    return mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "850903c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the original dataset into training and testing data\n",
    "training_data = data.iloc[:246116]\n",
    "y = training_data.close\n",
    "test_data = data.iloc[246117:]\n",
    "#drop 'close' column because that is our target value and drop 'date' column because it is not a continous value to use in predicting\n",
    "drop_features = ['date', 'close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "352455df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      0\n",
      "open      6\n",
      "high      3\n",
      "low       3\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check which values in training data contain null/NA values\n",
    "missing_values_in_training_data = training_data.isnull().sum()\n",
    "print(missing_values_in_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2584ab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      0\n",
      "open      5\n",
      "high      5\n",
      "low       5\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check for NA/null values in testing data \n",
    "missing_values_in_test_data = test_data.isnull().sum()\n",
    "print(missing_values_in_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cdd43579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop features/columns not needed/helpful for prediction\n",
    "training_data = training_data.drop(drop_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1a0e6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training_data into train data for training model and valid data to check the accuracy of the model\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(training_data,y, train_size = 0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5ffb90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use SimpleImputer method to fill in all empty/NA values with mean values\n",
    "my_imputer = SimpleImputer()\n",
    "imputated_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputated_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "imputated_X_train.columns = X_train.columns\n",
    "imputated_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "064bd758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating different RandomForestRegressor models with different parameters. The goal is to see which model is the best to use for prediction.\n",
    "rfr_model_1 = RandomForestRegressor(n_estimators = 150, random_state = 0)\n",
    "rfr_model_2 = RandomForestRegressor(max_depth = 15, random_state = 0, criterion='squared_error')\n",
    "rfr_model_3 = RandomForestRegressor(min_impurity_decrease = 0.6, random_state = 0, criterion='poisson')\n",
    "rfr_model_4 = RandomForestRegressor(max_features = 'sqrt', random_state = 0)\n",
    "rfr_model_5 = RandomForestRegressor(n_estimators = 400, random_state = 0)\n",
    "\n",
    "rfr_models = [rfr_model_1, rfr_model_2, rfr_model_3, rfr_model_4, rfr_model_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11f0cb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  1 \t Mean Absolute Error score: 0.3698874203775933\n",
      "Model  2 \t Mean Absolute Error score: 0.36608309243757786\n",
      "Model  3 \t Mean Absolute Error score: 44.0757026459739\n",
      "Model  4 \t Mean Absolute Error score: 0.3726542569275146\n",
      "Model  5 \t Mean Absolute Error score: 0.36931374382415216\n"
     ]
    }
   ],
   "source": [
    "#Pass each model to the score_tester function with the necessary train and valid data to check the accuracy of each model\n",
    "count = 1\n",
    "for model in rfr_models:\n",
    "    score = score_tester(model, imputated_X_train, imputated_X_valid, y_train, y_valid)\n",
    "    print(\"Model \",count,\"\\t Mean Absolute Error score:\", score)\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8ea526c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the actual 'close' values we will like to predict from the testing data\n",
    "actual_values = test_data.close\n",
    "test_data = test_data.drop(drop_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4b9a1ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all NA/null values in test data with mean values\n",
    "my_imputer = SimpleImputer()\n",
    "imputated_test_data = pd.DataFrame(my_imputer.fit_transform(test_data))\n",
    "\n",
    "imputated_test_data.columns = test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c087cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the 'close' values using the test data with replaced NA values\n",
    "predictions = rfr_model_2.predict(imputated_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4fb1a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Actual values  predictions\n",
      "symbol                            \n",
      "AAPL           105.35   104.103881\n",
      "AAP            152.24   152.143892\n",
      "ABBV            57.61    57.000162\n",
      "ABC            101.87   102.015560\n",
      "ABT             42.93    42.948886\n",
      "...               ...          ...\n",
      "XYL             68.20    68.344624\n",
      "YUM             81.61    82.060490\n",
      "ZBH            120.67   121.243403\n",
      "ZION            50.83    51.124386\n",
      "ZTS             72.04    72.371621\n",
      "\n",
      "[251355 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "combined = {'Actual values': actual_values, 'predictions': predictions}\n",
    "output_df = pd.DataFrame(combined)\n",
    "output_df.to_csv('output.csv', encoding='utf-8')\n",
    "print(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "99f4722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle library to serialize model object\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73759b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the best model to a pickle file\n",
    "with open('stock_price_model', 'wb') as f:\n",
    "    pickle.dump(rfr_model_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9bc0ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload the pickle file as a model object\n",
    "with open('stock_price_model', 'rb') as f:\n",
    "    mp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bec56ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([104.10388105, 152.14389185,  57.00016194, ..., 121.24340284,\n",
       "        51.12438582,  72.37162085])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test if model makes same prediction after being serialized\n",
    "mp.predict(imputated_test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
